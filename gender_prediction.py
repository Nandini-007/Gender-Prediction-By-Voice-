# -*- coding: utf-8 -*-
"""Gender_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zwdx268RQA3bug8BpW4UluESXBO5Q-OI
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import sklearn.model_selection, sklearn.linear_model, sklearn.svm, sklearn.metrics, sklearn.preprocessing, sklearn.pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
warnings.filterwarnings('ignore')

#Load CSV file into Dataframe
df= pd.read_csv("/content/voice.csv")

df.head(5)

#Data PreProcesing

df.info()

df.isnull().sum()

df.isnull().sum().sum()

# encodeing labels from string to bool
df.replace(to_replace='male', value=0, inplace=True)
df.replace(to_replace='female', value=1, inplace=True)

x=df.iloc[:,:-1]
y=df.iloc[:,-1]
x.shape,y.shape

# Splitting the data into Trainig and Testing
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=1)
x_train.shape,x_test.shape,y_train.shape,y_test.shape

print(x_train[:5])

#Data Visualization
plt.figure(figsize=(4,4))
plt.subplot(1,1,1)

df.label.value_counts().plot(kind='pie',
                             fontsize=10,
                             labels=["Male","Female"],
                             ylabel="Male Vs Female",
                             autopct='%1.1f%%',
                             colors=['#89CFF0','#FFB6C1']);
plt.show()
plt.figure(figsize=(4,6))
plt.subplot(1,2,2)
sns.countplot(x='label',data=df,
              order=df['label'].value_counts().index,
              palette='pastel')

plt.show()



plt.figure(figsize=(10,8))
data = df.corr()["label"].sort_values(ascending=False)
indices = data.index.values
labels = []
corr = []
for i in range(1, len(indices)):
    labels.append(indices[i])
    corr.append(data[i])
sns.barplot(x=corr, y=labels, palette='viridis')
plt.title('Correlation Coefficient between Different Features and Label')
plt.xlabel('Correlation Coefficient')
plt.ylabel('Features')
for i, v in enumerate(corr):
    plt.text(v + 0.02, i, str(round(v, 2)), color='black', va='center')
plt.show()

#Correaltion Coefficent
corr=df.corr()
#Heatmap
plt.figure(figsize=(12,10))
sns.heatmap(corr, annot=True, cmap='twilight', fmt=".2f")
plt.title('Correlation Matrix Heatmap')
plt.show()
#Clustermap
plt.figure(figsize=(12,10))
sns.clustermap(corr, cmap='cividis', annot=True, fmt=".2f")
plt.title('Clustermap of Correlation Matrix')
plt.show()

plt.figure(figsize=(20, 8))
sns.histplot(df.meanfreq, color=sns.color_palette('pastel')[0])
plt.title('Distribution of Meanfun')
plt.xlabel('Meanfun')
plt.ylabel('Frequency')
plt.show()

#Logistic Regression
LR= LogisticRegression(solver='liblinear')
LR.fit(x_train,y_train)
LRC_train=LR.score(x_train,y_train)
print("Logistic Regression Training Accuracy:",LRC_train,'\n')
y_pred = LR.predict(x_test)
accuracy_LRC = accuracy_score(y_test, y_pred)
print("Accuracy of Logitic Regression:",accuracy_LRC,'\n')
print("Classification Report:\n",classification_report(y_test, y_pred))
plt.figure(figsize=(4, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True).set(title='Logistic Regression')

from re import X
#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(x_train)
X_test = sc.transform(x_test)
LR = LogisticRegression()
LR.fit(X_train, y_train)
LR_train = LR.score(X_train, y_train)
print("Logistic Regression Training Accuracy:",LR_train,'\n')
y_pred = LR.predict(X_test)
accuracy_LR= accuracy_score(y_test, y_pred)
print("Accuracy of Logitic Regression:",accuracy_LR,'\n')
print("Classification Report:\n",classification_report(y_test, y_pred))
plt.figure(figsize=(4, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True).set(title='Logistic Regression')

print(X_train[:5])

print(x_train[:5])

#K-Nearest Neighbor
KNN= KNeighborsClassifier(n_neighbors=3)
KNN.fit(x_train,y_train)
KNN_pred=KNN.predict(x_test)
KN_train=KNN.score(x_train,y_train)
print("KNN Training Accuracy:",KN_train,'\n')
accuracy_KN= accuracy_score(y_test,KNN_pred)
print("Accuracy of KNN:",accuracy_KN,'\n')
print("Classification Report:\n",classification_report(y_test, KNN_pred))
plt.figure(figsize=(4, 4))
sns.heatmap(confusion_matrix(y_test, KNN_pred), annot=True).set(title='KNN')

#Train model using Scaling Feature
from sklearn.preprocessing import MinMaxScaler
scc=MinMaxScaler()
X_train=scc.fit_transform(x_train)
X_test=scc.transform(x_test)
KNN= KNeighborsClassifier(n_neighbors=3)
KNN.fit(X_train,y_train)
KNN_train=KNN.score(X_train,y_train)
print("KNN Training Accuracy:",KNN_train,'\n')
KNN_pred=KNN.predict(X_test)
accuracy_KNN= accuracy_score(y_test,KNN_pred)
print("Accuracy of KNN:",accuracy_KNN,'\n')
print("Classification Report:\n",classification_report(y_test, KNN_pred))
plt.figure(figsize=(4, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True).set(title='Logistic Regression')

#SVM Model
SVM=SVC(kernel='linear',C=10)
SVM.fit(x_train,y_train)
SVM_train=SVM.score(x_train,y_train)
print("SVM Training Accuracy:",SVM_train,'\n')
SVM_pred=SVM.predict(x_test)
accuracy_SVM= accuracy_score(y_test,SVM_pred)

print("Accuracy of SVM:",accuracy_SVM,'\n')
print("Classification Report:\n",classification_report(y_test, SVM_pred))
plt.figure(figsize=(4, 4))
sns.heatmap(confusion_matrix(y_test, SVM_pred), annot=True).set(title='SVM')

#Random Forest
RF=RandomForestClassifier(n_estimators=100)
RF.fit(x_train,y_train)
RF_train=RF.score(x_train,y_train)
print("Random Forest Training Accuracy:",RF_train,'\n')
RF_pred=RF.predict(x_test)
accuracy_RF= accuracy_score(y_test,RF_pred)
print("Accuracy of Random Forest:",accuracy_RF,'\n')
print("Classification Report:\n",classification_report(y_test, RF_pred))
plt.figure(figsize=(4, 4))
sns.heatmap(confusion_matrix(y_test, RF_pred), annot=True).set(title='Random Forest')

#Decision Tree
DT= DecisionTreeClassifier()
DT.fit(x_train,y_train)
DT_train=DT.score(x_train,y_train)
print("Decision Tree Train Score:",DT_train,'\n')
DT_pred=DT.predict(x_test)
accuracy_DT= accuracy_score(y_test,DT_pred)
print("Accuracy of Decision Tree:",accuracy_DT,'\n')
print("Classification Report:\n",classification_report(y_test, DT_pred))
plt.figure(figsize=(4, 4))
sns.heatmap(confusion_matrix(y_test, DT_pred), annot=True).set(title='Decision Tree')

#Gaussian Process Classifier
Gp= GaussianProcessClassifier()
Gp.fit(x_train,y_train)
Gp_train=Gp.score(x_train,y_train)
print("Gaussian Process Classifier Train Score:",Gp_train,'\n')
Gp_pred=Gp.predict(x_test)
accuracy_Gp= accuracy_score(y_test,Gp_pred)
print("Accuracy of Gaussian Process Classifier:",accuracy_Gp,'\n')
print("Classification Report:\n",classification_report(y_test,Gp_pred))
plt.figure(figsize=(4, 4))
sns.heatmap(confusion_matrix(y_test, Gp_pred), annot=True).set(title='Gaussian Process Classifier')

#Performance Anaylsis
models = ['Logistic Regression', 'KNN', 'SVM', 'Random Forest', 'Decision Tree', 'Gaussian Process']
accuracies = [accuracy_LRC, accuracy_KN, accuracy_SVM, accuracy_RF, accuracy_DT, accuracy_Gp]
training=[LR_train,KN_train,SVM_train,RF_train, DT_train,Gp_train]

scores = pd.DataFrame({'Training Score': training,'Testing Score': accuracies}, index= models)
plot = scores.plot.bar(figsize=(16, 8), rot=0, color=['#1D5C92', '#A55211'])
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Performance Analysis of Different Models")
plt.legend(loc='best')
plt.show()

print(scores)